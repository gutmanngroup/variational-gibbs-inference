{
    "model_seed": 20190508,
    "data_seeds": [20200325, 20200406, 20200407],
    "exp_group": "toy_set3_mar/learning_experiments/3",
    "experiment_name": "var_pretraining_test",
    "data": {
        "dataset": "toy_set3",
        "num_imputed_copies": [5],
        "total_miss": 0.5,
        "miss_type": "MAR",
        "max_patterns": 50,
        "filter_fully_missing": true,
        "pre_imputation": "empirical_distribution_samples",
        "batch_size": 2048
    },
    "method": "var-pretraining",
    // Variational model used - individual per distribution or partially shared
    "variational_model": "individual",
    "var_model": {
        "activation": "lrelu",
        "input_missing_vectors": false,
        "input_dim": 5,
        "num_univariate_q": 6,
        "hidden_dims": [3]
    },
    //
    // Trainer parameters
    //
    "max_epochs": 100,
    "optim": {
        "optimiser": "amsgrad",
        "learning_rate": 1e-1, 
        "weight_decay_coeff": 0.0
    }
}
