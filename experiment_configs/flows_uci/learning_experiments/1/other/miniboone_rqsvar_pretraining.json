{
    "model_seed": 20190508,
    "data_seeds": [20200325, 20200406, 20200407],
    "exp_group": "flows_uci/learning_experiments/1",
    "experiment_name": "miniboone_rqsvar_pretraining",
    "data": {
        "dataset": "uci_miniboone",
        "num_imputed_copies": [5],
        "total_miss": 0.1667,
        "miss_type": "MCAR",
        "filter_fully_missing": true,
        "pre_imputation": "empirical_distribution_samples",
        "batch_size": 128
    },
    "method": "var-pretraining",
    "variational_model": "rq-flow",
    "var_model": {
        "activation": "lrelu",
        "input_dim": 43,
        "encoder_hidden_features": 256,
        "encoder_num_blocks": 1,
        // "context_intermediate_features": 128,
        "context_intermediate_features": 100,

        // "hidden_features": 64,
        "hidden_features": 512,
        "num_transform_blocks": 2,
        // "num_blocks": 1,
        "num_blocks": 2,
        "num_flow_steps": 3,
        "tail_bound": 3,
        "num_bins": 4,

        "dropout_probability": 0.0,
        "use_batch_norm": false

        // "body_hidden_dims": [256, 256, 128],
        // "head_hidden_dims": [64, 64]
    },
    //
    // Trainer parameters
    //
    "max_epochs": 200,
    // Effective batch size is data.batch_size x accumulate_grad_batches
    "accumulate_grad_batches": 1,
    "optim": {
        "optimiser": "amsgrad",
        "learning_rate": 1e-4,
        "weight_decay_coeff": 0.0,
        "anneal_learning_rate": true
    }
}
